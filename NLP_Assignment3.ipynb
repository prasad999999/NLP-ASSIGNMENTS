{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dqxLK2lLhC4e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK data (ensure it's available for lemmatization and stopwords)\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njoUPPWkjfUd",
        "outputId": "7fa8c296-8d39-441d-a1b0-4e8ec3ac3858"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data (replace this with your own dataset)\n",
        "data = {\n",
        "    'text': [\n",
        "        \"Cats are running in the garden.\",\n",
        "        \"The dog is barking loudly!\",\n",
        "        \"I love programming in Python.\",\n",
        "        \"Python is an amazing language.\",\n",
        "        \"Dogs and cats can be great pets.\"\n",
        "    ],\n",
        "    'label': ['animal', 'animal', 'coding', 'coding', 'animal']\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphanumeric characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = text.strip()  # Remove leading/trailing whitespace\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "kRa1sr4TjlTd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization and stop word removal\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['processed_text'] = df['cleaned_text'].apply(preprocess_text)\n",
        "\n",
        "# Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "df['label_encoded'] = label_encoder.fit_transform(df['label'])"
      ],
      "metadata": {
        "id": "UYmRyh74k2iP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF vectorization\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(df['processed_text'])\n",
        "\n",
        "# Convert TF-IDF matrix to DataFrame\n",
        "tfidf_df = pd.DataFrame(\n",
        "    tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out()\n",
        ")\n",
        "\n",
        "# Save outputs to CSV files\n",
        "df.to_csv('processed_texts.csv', index=False)\n",
        "tfidf_df.to_csv('tfidf_features.csv', index=False)\n",
        "\n",
        "# Display results\n",
        "print(\"Processed DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nTF-IDF Features:\")\n",
        "print(tfidf_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0nXDc5qlPFg",
        "outputId": "5d87f239-98fc-4379-e969-cce5ea97af76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed DataFrame:\n",
            "                               text   label                     cleaned_text  \\\n",
            "0   Cats are running in the garden.  animal   cats are running in the garden   \n",
            "1        The dog is barking loudly!  animal        the dog is barking loudly   \n",
            "2     I love programming in Python.  coding     i love programming in python   \n",
            "3    Python is an amazing language.  coding    python is an amazing language   \n",
            "4  Dogs and cats can be great pets.  animal  dogs and cats can be great pets   \n",
            "\n",
            "            processed_text  label_encoded  \n",
            "0       cat running garden              0  \n",
            "1       dog barking loudly              0  \n",
            "2  love programming python              1  \n",
            "3  python amazing language              1  \n",
            "4        dog cat great pet              0  \n",
            "\n",
            "TF-IDF Features:\n",
            "    amazing   barking       cat       dog    garden     great  language  \\\n",
            "0  0.000000  0.000000  0.495524  0.000000  0.614189  0.000000  0.000000   \n",
            "1  0.000000  0.614189  0.000000  0.495524  0.000000  0.000000  0.000000   \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "3  0.614189  0.000000  0.000000  0.000000  0.000000  0.000000  0.614189   \n",
            "4  0.000000  0.000000  0.444002  0.444002  0.000000  0.550329  0.000000   \n",
            "\n",
            "     loudly      love       pet  programming    python   running  \n",
            "0  0.000000  0.000000  0.000000     0.000000  0.000000  0.614189  \n",
            "1  0.614189  0.000000  0.000000     0.000000  0.000000  0.000000  \n",
            "2  0.000000  0.614189  0.000000     0.614189  0.495524  0.000000  \n",
            "3  0.000000  0.000000  0.000000     0.000000  0.495524  0.000000  \n",
            "4  0.000000  0.000000  0.550329     0.000000  0.000000  0.000000  \n"
          ]
        }
      ]
    }
  ]
}