{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V0-bWn5ObRD"
   },
   "source": [
    "# **Basic NLP Tokenization, Stemming and Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ikoyYPqYKmn-",
    "outputId": "94035b53-7147-4f3c-8026-63219890e036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in e:\\programdata\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in e:\\programdata\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\programdata\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\programdata\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in e:\\programdata\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in e:\\programdata\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at e:\\programdata\\lib\\site-packages\\diamondpriceprediction-0.0.1-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at e:\\programdata\\lib\\site-packages\\fonttools-4.53.0-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at e:\\programdata\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4g1nW-oSLRAK",
    "outputId": "8cb0e0f1-e053-4d84-ffc6-88b805d47239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'random', 'sentence', 'generated', 'using', 'human', 'intelligence.', '(trial)']\n",
      "['This', 'is', 'a', 'random', 'sentence', 'generated', 'using', 'human', 'intelligence.', '(', 'trial', ')']\n",
      "['This is a random sentence generated using human intelligence.', '(trial)']\n",
      "['This', 'is', 'a', 'random', 'sentence', 'generated', 'using', 'human', 'intelligence', '.', '(', 'trial', ')']\n",
      "['T', 'h', 'i', 's', ' ', 'i', 's', ' ', 'a', ' ', 'r', 'a', 'n', 'd', 'o', 'm', ' ', 's', 'e', 'n', 't', 'e', 'n', 'c', 'e', ' ', 'g', 'e', 'n', 'e', 'r', 'a', 't', 'e', 'd', ' ', 'u', 's', 'i', 'n', 'g', ' ', 'h', 'u', 'm', 'a', 'n', ' ', 'i', 'n', 't', 'e', 'l', 'l', 'i', 'g', 'e', 'n', 'c', 'e', '.', ' ', '(', 't', 'r', 'i', 'a', 'l', ')']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer, TreebankWordTokenizer, PunktSentenceTokenizer, TweetTokenizer, MWETokenizer\n",
    "\n",
    "WT = WhitespaceTokenizer()\n",
    "DT = TreebankWordTokenizer()\n",
    "PT = PunktSentenceTokenizer()\n",
    "TT = TweetTokenizer()\n",
    "MW = MWETokenizer()\n",
    "\n",
    "sent = \"This is a random sentence generated using human intelligence. (trial)\"\n",
    "\n",
    "print(WT.tokenize(sent))\n",
    "print(DT.tokenize(sent))\n",
    "print(PT.tokenize(sent))\n",
    "print(TT.tokenize(sent))\n",
    "print(MW.tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJ9ALwJWKGHW",
    "outputId": "41980d78-e5b3-45e7-8402-c6832cf621c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ah1QrmgIMRos",
    "outputId": "9f7c63d5-debf-4542-b17f-ee2b8c9f986c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer Output:\n",
      "running -> run\n",
      "runner -> runner\n",
      "runs -> run\n",
      "swimming -> swim\n",
      "swimmer -> swimmer\n",
      "swims -> swim\n",
      "\n",
      "Snowball Stemmer Output:\n",
      "running -> run\n",
      "runner -> runner\n",
      "runs -> run\n",
      "swimming -> swim\n",
      "swimmer -> swimmer\n",
      "swims -> swim\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer(language='english')\n",
    "\n",
    "words = [\"running\", \"runner\", \"runs\", \"swimming\", \"swimmer\", \"swims\"]\n",
    "stemmed_words = [porter.stem(word) for word in words]\n",
    "\n",
    "print(\"Porter Stemmer Output:\")\n",
    "for original, stemmed in zip(words, stemmed_words):\n",
    "    print(f\"{original} -> {stemmed}\")\n",
    "\n",
    "print(\"\\nSnowball Stemmer Output:\")\n",
    "for original, stemmed in zip(words, stemmed_words):\n",
    "    print(f\"{original} -> {stemmed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FlYAJTONNKJ6",
    "outputId": "bc0c130f-2e32-4a85-a5ba-4c32fa89de8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
    "\n",
    "# a denotes adjective in \"pos\"\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos=\"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lT9rSrj8Ognl"
   },
   "source": [
    "# **Added Text file based NLP Tokenization, Stemming and Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3izYpOvtjc1",
    "outputId": "e75d6bc1-7363-450d-d3b6-ea542bcbcfc8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1n8WX2C3OkyE",
    "outputId": "2db80561-19eb-4b24-c0d5-187364adf678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitespace Tokenizer: ['\"Jumping', 'joyfully,', 'the', 'quick', 'brown', 'fox', 'localized', 'itself', 'near', 'a', 'running', 'stream', 'in', 'a', 'highly-intelligent', 'AI-driven', 'system.\"']\n",
      "Treebank Tokenizer: ['``', 'Jumping', 'joyfully', ',', 'the', 'quick', 'brown', 'fox', 'localized', 'itself', 'near', 'a', 'running', 'stream', 'in', 'a', 'highly-intelligent', 'AI-driven', 'system', '.', \"''\"]\n",
      "Punkt Sentence Tokenizer: ['\"Jumping joyfully, the quick brown fox localized itself near a running stream in a highly-intelligent AI-driven system.\"']\n",
      "Tweet Tokenizer: ['\"', 'Jumping', 'joyfully', ',', 'the', 'quick', 'brown', 'fox', 'localized', 'itself', 'near', 'a', 'running', 'stream', 'in', 'a', 'highly-intelligent', 'AI-driven', 'system', '.', '\"']\n",
      "MWETokenizer (basic): ['\"Jumping', 'joyfully,', 'the', 'quick', 'brown', 'fox', 'localized', 'itself', 'near', 'a', 'running', 'stream', 'in', 'a', 'highly-intelligent', 'AI-driven', 'system.\"']\n",
      "PorterStemmer Examples:\n",
      "localization: local\n",
      "jumping: jump\n",
      "running: run\n",
      "SnowballStemmer Examples:\n",
      "localization: local\n",
      "jumping: jump\n",
      "running: run\n",
      "Lemmatizer Examples:\n",
      "jumping (verb): jump \n",
      "running (verb): run \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer, TreebankWordTokenizer, PunktSentenceTokenizer, TweetTokenizer, MWETokenizer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Tokenizers\n",
    "WT = WhitespaceTokenizer()\n",
    "DT = TreebankWordTokenizer()\n",
    "PT = PunktSentenceTokenizer()\n",
    "TT = TweetTokenizer()\n",
    "MW = MWETokenizer()\n",
    "\n",
    "# Stemmers\n",
    "PS = PorterStemmer()\n",
    "SS = SnowballStemmer('english')\n",
    "\n",
    "# Lemmatizer\n",
    "WL = WordNetLemmatizer()\n",
    "\n",
    "# Function to process a text file\n",
    "def process_text_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Tokenization\n",
    "    print(\"Whitespace Tokenizer:\", WT.tokenize(text))\n",
    "    print(\"Treebank Tokenizer:\", DT.tokenize(text))\n",
    "    print(\"Punkt Sentence Tokenizer:\", PT.tokenize(text))\n",
    "    print(\"Tweet Tokenizer:\", TT.tokenize(text))\n",
    "    print(\"MWETokenizer (basic):\", MW.tokenize(text.split()))\n",
    "\n",
    "    # Stemming examples\n",
    "    print(\"PorterStemmer Examples:\")\n",
    "    for word in ['localization', 'jumping', 'running']:\n",
    "        print(f\"{word}: {PS.stem(word)}\")\n",
    "\n",
    "    print(\"SnowballStemmer Examples:\")\n",
    "    for word in ['localization', 'jumping', 'running']:\n",
    "        print(f\"{word}: {SS.stem(word)}\")\n",
    "\n",
    "    # Lemmatization examples\n",
    "    print(\"Lemmatizer Examples:\")\n",
    "    for word in ['jumping', 'running']:\n",
    "        print(f\"{word} (verb): {WL.lemmatize(word, 'v')} \")\n",
    "\n",
    "# Example usage\n",
    "# Place the text file path below\n",
    "process_text_file('/content/sample.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XX_eZs5Yt16r"
   },
   "source": [
    "# **Added Pdf file based NLP Tokenization, Stemming and Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkdqLC2SuuZT",
    "outputId": "ad761a7f-aef4-467f-84a5-046675f09ef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PdfReader in /usr/local/lib/python3.11/dist-packages (0.1.15)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: bitarray>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from PdfReader) (3.0.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from PdfReader) (11.1.0)\n",
      "Requirement already satisfied: pycryptodome>=3.9.9 in /usr/local/lib/python3.11/dist-packages (from PdfReader) (3.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from PdfReader) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->PdfReader) (1.17.0)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PdfReader PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0r5VuvJtslK",
    "outputId": "d38c0a67-52f0-4083-aaa0-53dd3fd3b960"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitespace Tokenizer: ['Nishchay', 'Bhardwaj', 'nishchaybhardwaj1.9@gmail.com', '•', '+91', '9325046223', '•', 'Portfolio', 'EDUCATION', 'BRACT’s', 'Vishwakarma', 'Institute', 'of', 'Information', 'Technology,', 'Pune', 'Oct', '2022', '–', 'May', '2026', 'Bachelor', 'of', 'Technology,', 'Computer', 'Science', '-', 'Artificial', 'Intelligence', 'CGPA:', '9.02', 'Relevant', 'coursework:', 'Machine', 'Learning,', 'Artificial', 'Intelligence,', 'Deep', 'Learning,', 'Data', 'Structures', 'and', 'Algorithms', ',', 'Web', 'Development,', 'Database', 'Management', 'Asian', 'College', 'of', 'Science', 'and', 'Commerce,', 'Pune', 'Apr', '2020', '–', 'May', '2021', '12th', 'Standard', 'Percentage:', '80.6%', 'INTERNSHIP', 'EXPERIENCE', 'Ratnamukund', 'HealthCare', 'Foundation', '2024', '(Latest)', 'Full', 'Stack', 'Developer', '•', 'Developed', 'a', 'website', 'using', 'Next.js', 'and', 'Tailwind', 'CSS', 'for', 'frontend,', 'and', 'Strapi', 'with', 'MySQL', 'for', 'backend.', '•', 'Integrated', 'APIs', '(OpenStreetMap,', 'Leaflet,', 'Meta', 'Console)', 'and', 'used', 'Git', 'for', 'version', 'control', 'and', 'Vercel', 'for', 'deployment.', 'PROJECTS', '&', 'EXTRACURRICULAR', 'Human', 'Pose', 'Estimation', 'using', 'Machine', 'Learning', 'May', '2024', '•', 'Compared', 'models', 'of', 'MoveNet', 'and', 'YOLOv8', 'for', 'classifying', 'yoga', 'poses', '(downdog,', 'goddess,', 'tree,', 'plank,', 'warrior),', 'concluding', 'that', 'MoveNet', 'achieved', 'higher', 'accuracy.', '•', 'Employed', 'Python', ',', 'TensorFlow', ',', 'and', 'OpenCV', ',', 'enhancing', 'understanding', 'of', 'model', 'evaluation', 'and', 'accuracy', 'metrics.', 'Smart', 'Campus', 'Management', 'System', 'September', '2024', '•', 'Developed', 'an', 'attendance', 'tracking', 'system', 'using', 'OpenCV', 'face', 'recognition', 'and', 'a', 'chatbot', '-powered', 'timetable', 'generator', 'with', 'Bard', 'API.', 'Used', 'Next.js', ',', 'Tailwind', 'CSS', ',', 'and', 'Strapi', 'to', 'create', 'an', 'intuitive', 'user', 'interface', 'and', 'backend', 'for', 'efficient', 'data', 'handling.', 'J.P.', 'Morgan', 'Software', 'Engineering', 'Virtual', 'Experience', '(Forage)', 'October', '2024', '•', 'Set', 'up', 'a', 'local', 'dev', 'environment', 'and', 'used', 'JPMorgan', 'Chase’s', 'open', '-source', 'library,', 'Perspective,', 'to', 'generate', 'a', 'live', 'graph', 'that', 'displays', 'data', 'feed,', 'supporting', 'traders', 'in', 'monitoring', 'data', 'in', 'real', '-time.', 'Activity', 'July', '2023', '–', 'October', '2024', '•', 'Worked', 'on', 'Human', 'Pose', 'Estimation', 'at', 'Hacknovate', '-2k24', 'and', 'Smart', 'Campus', 'Management', 'in', 'Vortexa', 'Hackathon', '.', '•', 'Presented', 'chatbot', 'implementation', 'for', 'Railway', 'Industry', 'at', 'Smart', 'India', 'Hackathon', '.', 'Leadership', 'experience', 'September', '2024', '-', 'Present', '•', 'Web', 'Development', 'Head', 'of', 'CodeChef', 'Forum', 'at', 'VIIT', '.', '•', 'Participated', 'in', 'a', 'leadership', 'camp', 'organized', 'by', 'VIIT,', 'focusing', 'on', 'team', '-building', 'and', 'leadership', 'skills', 'development.', 'RESEARCH', 'PAPER', '&', 'PUBLICATIONS', 'Paper', 'Title:', '\"Human', 'Pose', 'Estimation', 'using', 'Machine', 'Learning', '\"', 'October', '2024', '•', 'Presented', 'on', 'October', '16,', '2024,', 'at', 'ASCIS', '2024', '(Springer).', 'SKILLS', 'Programming', 'Languages', ':', 'Python,', 'C,', 'C++,', 'Java', 'Artificial', 'Intelligence', ':', 'Natural', 'Language', 'Processing', '(NLP),', 'Computer', 'Vision', '(Image', 'Classification,', 'Object', 'Detection),', 'Reinforcement', 'Learning', 'Machine', 'Learning', ':', 'TensorFlow,', 'Keras,', 'scikit', '-learn,', 'PyTorch', 'Web', 'Development', ':', 'HTML,', 'CSS,', 'JavaScript,', 'React.js,', 'Next.js,', 'Express.js,', 'Node.js,', 'Tailwind,', 'Flask', 'Databases', ':', 'MySQL,', 'MongoDB', 'DevOps', '&', 'Software', 'Engineering', ':', 'Agile', 'Methodologies,', 'Continuous', 'Integration/Continuous', 'Deployment', '(CI/CD),', 'Version', 'Control', '(Git,', 'GitHub)', ',', 'Jira,', 'Kanban,', 'Docker', 'RESTful', 'APIs', ':', 'Experience', 'with', 'Postman', 'for', 'API', 'testing', 'and', 'documentation', 'Soft', 'Skills', ':', 'Problem', '-solving,', 'critical', 'thinking,', 'collaboration,', 'communication,', 'determination', 'CERTIFICATIONS', '•', 'IBM', 'Certified', 'for', 'DevOps', 'and', 'Software', 'Engineering', '•', 'NVIDIA', 'Certified', 'for', 'Fundamentals', 'of', 'Deep', 'Learning', '•', 'CDAC', 'Certified', 'for', 'Basic', 'Certification', 'Course', 'in', 'Artificial', 'Intelligence', '•', 'Skolar', 'Certified', 'for', 'Full', 'Stack', 'Web', 'Development', '•', 'Infosys', 'Certified', 'for', 'Python', 'Fundamentals', 'LINKS', '•', 'GitHub', '-', 'NishchayBhardwaj', '•', 'LinkedIn', '-', 'nishchay', '-bhardwaj', '•', 'LeetCode', '-', 'Nishchay', '-Bhardwaj', '•', 'Coding', 'Ninjas', '-', 'nishchay', 'bhardwaj']\n",
      "Treebank Tokenizer: ['Nishchay', 'Bhardwaj', 'nishchaybhardwaj1.9', '@', 'gmail.com', '•', '+91', '9325046223', '•', 'Portfolio', 'EDUCATION', 'BRACT’s', 'Vishwakarma', 'Institute', 'of', 'Information', 'Technology', ',', 'Pune', 'Oct', '2022', '–', 'May', '2026', 'Bachelor', 'of', 'Technology', ',', 'Computer', 'Science', '-', 'Artificial', 'Intelligence', 'CGPA', ':', '9.02', 'Relevant', 'coursework', ':', 'Machine', 'Learning', ',', 'Artificial', 'Intelligence', ',', 'Deep', 'Learning', ',', 'Data', 'Structures', 'and', 'Algorithms', ',', 'Web', 'Development', ',', 'Database', 'Management', 'Asian', 'College', 'of', 'Science', 'and', 'Commerce', ',', 'Pune', 'Apr', '2020', '–', 'May', '2021', '12th', 'Standard', 'Percentage', ':', '80.6', '%', 'INTERNSHIP', 'EXPERIENCE', 'Ratnamukund', 'HealthCare', 'Foundation', '2024', '(', 'Latest', ')', 'Full', 'Stack', 'Developer', '•', 'Developed', 'a', 'website', 'using', 'Next.js', 'and', 'Tailwind', 'CSS', 'for', 'frontend', ',', 'and', 'Strapi', 'with', 'MySQL', 'for', 'backend.', '•', 'Integrated', 'APIs', '(', 'OpenStreetMap', ',', 'Leaflet', ',', 'Meta', 'Console', ')', 'and', 'used', 'Git', 'for', 'version', 'control', 'and', 'Vercel', 'for', 'deployment.', 'PROJECTS', '&', 'EXTRACURRICULAR', 'Human', 'Pose', 'Estimation', 'using', 'Machine', 'Learning', 'May', '2024', '•', 'Compared', 'models', 'of', 'MoveNet', 'and', 'YOLOv8', 'for', 'classifying', 'yoga', 'poses', '(', 'downdog', ',', 'goddess', ',', 'tree', ',', 'plank', ',', 'warrior', ')', ',', 'concluding', 'that', 'MoveNet', 'achieved', 'higher', 'accuracy.', '•', 'Employed', 'Python', ',', 'TensorFlow', ',', 'and', 'OpenCV', ',', 'enhancing', 'understanding', 'of', 'model', 'evaluation', 'and', 'accuracy', 'metrics.', 'Smart', 'Campus', 'Management', 'System', 'September', '2024', '•', 'Developed', 'an', 'attendance', 'tracking', 'system', 'using', 'OpenCV', 'face', 'recognition', 'and', 'a', 'chatbot', '-powered', 'timetable', 'generator', 'with', 'Bard', 'API.', 'Used', 'Next.js', ',', 'Tailwind', 'CSS', ',', 'and', 'Strapi', 'to', 'create', 'an', 'intuitive', 'user', 'interface', 'and', 'backend', 'for', 'efficient', 'data', 'handling.', 'J.P.', 'Morgan', 'Software', 'Engineering', 'Virtual', 'Experience', '(', 'Forage', ')', 'October', '2024', '•', 'Set', 'up', 'a', 'local', 'dev', 'environment', 'and', 'used', 'JPMorgan', 'Chase’s', 'open', '-source', 'library', ',', 'Perspective', ',', 'to', 'generate', 'a', 'live', 'graph', 'that', 'displays', 'data', 'feed', ',', 'supporting', 'traders', 'in', 'monitoring', 'data', 'in', 'real', '-time.', 'Activity', 'July', '2023', '–', 'October', '2024', '•', 'Worked', 'on', 'Human', 'Pose', 'Estimation', 'at', 'Hacknovate', '-2k24', 'and', 'Smart', 'Campus', 'Management', 'in', 'Vortexa', 'Hackathon', '.', '•', 'Presented', 'chatbot', 'implementation', 'for', 'Railway', 'Industry', 'at', 'Smart', 'India', 'Hackathon', '.', 'Leadership', 'experience', 'September', '2024', '-', 'Present', '•', 'Web', 'Development', 'Head', 'of', 'CodeChef', 'Forum', 'at', 'VIIT', '.', '•', 'Participated', 'in', 'a', 'leadership', 'camp', 'organized', 'by', 'VIIT', ',', 'focusing', 'on', 'team', '-building', 'and', 'leadership', 'skills', 'development.', 'RESEARCH', 'PAPER', '&', 'PUBLICATIONS', 'Paper', 'Title', ':', '``', 'Human', 'Pose', 'Estimation', 'using', 'Machine', 'Learning', '``', 'October', '2024', '•', 'Presented', 'on', 'October', '16', ',', '2024', ',', 'at', 'ASCIS', '2024', '(', 'Springer', ')', '.', 'SKILLS', 'Programming', 'Languages', ':', 'Python', ',', 'C', ',', 'C++', ',', 'Java', 'Artificial', 'Intelligence', ':', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', ',', 'Computer', 'Vision', '(', 'Image', 'Classification', ',', 'Object', 'Detection', ')', ',', 'Reinforcement', 'Learning', 'Machine', 'Learning', ':', 'TensorFlow', ',', 'Keras', ',', 'scikit', '-learn', ',', 'PyTorch', 'Web', 'Development', ':', 'HTML', ',', 'CSS', ',', 'JavaScript', ',', 'React.js', ',', 'Next.js', ',', 'Express.js', ',', 'Node.js', ',', 'Tailwind', ',', 'Flask', 'Databases', ':', 'MySQL', ',', 'MongoDB', 'DevOps', '&', 'Software', 'Engineering', ':', 'Agile', 'Methodologies', ',', 'Continuous', 'Integration/Continuous', 'Deployment', '(', 'CI/CD', ')', ',', 'Version', 'Control', '(', 'Git', ',', 'GitHub', ')', ',', 'Jira', ',', 'Kanban', ',', 'Docker', 'RESTful', 'APIs', ':', 'Experience', 'with', 'Postman', 'for', 'API', 'testing', 'and', 'documentation', 'Soft', 'Skills', ':', 'Problem', '-solving', ',', 'critical', 'thinking', ',', 'collaboration', ',', 'communication', ',', 'determination', 'CERTIFICATIONS', '•', 'IBM', 'Certified', 'for', 'DevOps', 'and', 'Software', 'Engineering', '•', 'NVIDIA', 'Certified', 'for', 'Fundamentals', 'of', 'Deep', 'Learning', '•', 'CDAC', 'Certified', 'for', 'Basic', 'Certification', 'Course', 'in', 'Artificial', 'Intelligence', '•', 'Skolar', 'Certified', 'for', 'Full', 'Stack', 'Web', 'Development', '•', 'Infosys', 'Certified', 'for', 'Python', 'Fundamentals', 'LINKS', '•', 'GitHub', '-', 'NishchayBhardwaj', '•', 'LinkedIn', '-', 'nishchay', '-bhardwaj', '•', 'LeetCode', '-', 'Nishchay', '-Bhardwaj', '•', 'Coding', 'Ninjas', '-', 'nishchay', 'bhardwaj']\n",
      "Punkt Sentence Tokenizer: ['Nishchay Bhardwaj   \\nnishchaybhardwaj1.9@gmail.com   •  +91 9325046223  •  Portfolio  \\nEDUCATION   \\n \\nBRACT’s Vishwakarma Institute of Information Technology, Pune  Oct 2022 – May 2026  \\nBachelor of Technology, Computer Science - Artificial Intelligence   \\nCGPA: 9.02  \\nRelevant coursework: Machine Learning, Artificial Intelligence,  Deep Learning, Data Structures  and \\nAlgorithms , Web Development, Database Management  \\nAsian College of Science and Commerce, Pune  Apr 2020 – May 2021   \\n12th Standard   \\nPercentage: 80.6%   \\n \\nINTERNSHIP EXPERIENCE   \\n \\nRatnamukund HealthCare Foundation  2024 (Latest)  \\nFull Stack Developer   \\n• Developed a website using Next.js  and Tailwind CSS  for frontend, and Strapi  with MySQL  for backend.', '• Integrated APIs  (OpenStreetMap, Leaflet, Meta Console) and used Git for version control and Vercel  for \\ndeployment.', 'PROJECTS & EXTRACURRICULAR   \\n \\nHuman Pose  Estimation using Machine Learning  May  2024  \\n• Compared models of MoveNet  and YOLOv8  for classifying yoga poses (downdog, goddess, tree, plank, \\nwarrior), concluding that MoveNet achieved higher accuracy.', '• Employed Python , TensorFlow , and OpenCV , enhancing understanding of model evaluation and \\naccuracy metrics.', 'Smart Campus Management System   September 2024  \\n• Developed an attendance tracking system using OpenCV  face recognition and a chatbot -powered timetable \\ngenerator with Bard  API.', 'Used Next.js , Tailwind CSS , and Strapi  to create an intuitive user interface and backend for efficient data \\nhandling.', 'J.P.', 'Morgan Software Engineering Virtual Experience (Forage)  October  2024  \\n• Set up a local dev environment and used JPMorgan Chase’s  open -source library, Perspective, to generate \\na live graph that displays data feed, supporting traders in monitoring data in real -time.', 'Activity  July 2023 – October 2024  \\n• Worked on Human Pose Estimation at Hacknovate -2k24  and Smart Campus Management in Vortexa  \\nHackathon .', '• Presented chatbot implementation for Railway Industry at Smart India Hackathon .', 'Leadership experience  September 2024 - Present  \\n• Web Development Head  of CodeChef  Forum  at VIIT .', '• Participated in a leadership camp organized by VIIT, focusing on team -building  and leadership  skills \\ndevelopment.', 'RESEARCH PAPER & PUBLICATIONS   \\n \\nPaper Title: \"Human Pose Estimation using Machine Learning \" October 2024  \\n• Presented on October 16, 2024, at ASCIS 2024  (Springer).', 'SKILLS   \\n \\nProgramming Languages : Python, C, C++, Java  \\nArtificial Intelligence : Natural Language Processing (NLP), Computer Vision (Image Classification, Object \\nDetection), Reinforcement Learning  \\nMachine Learning : TensorFlow, Keras, scikit -learn, PyTorch  \\nWeb Development : HTML, CSS, JavaScript, React.js, Next.js, Express.js, Node.js, Tailwind, Flask  \\nDatabases : MySQL, MongoDB  \\nDevOps & Software Engineering : Agile Methodologies, Continuous Integration/Continuous Deployment (CI/CD), \\nVersion Control (Git, GitHub) , Jira, Kanban, Docker  \\nRESTful APIs : Experience with Postman for API testing and documentation  \\nSoft Skills : Problem -solving, critical thinking, collaboration, communication, determination  \\n \\nCERTIFICATIONS   \\n \\n• IBM Certified for DevOps and Software Engineering  \\n• NVIDIA Certified for Fundamentals of Deep Learning  \\n• CDAC Certified for Basic Certification Course in Artificial Intelligence  \\n• Skolar Certified for  Full Stack Web Development  \\n• Infosys Certified for Python Fundamentals  \\n \\nLINKS   \\n \\n• GitHub - NishchayBhardwaj  \\n• LinkedIn - nishchay -bhardwaj  \\n• LeetCode - Nishchay -Bhardwaj  \\n• Coding Ninjas - nishchay bhardwaj']\n",
      "Tweet Tokenizer: ['Nishchay', 'Bhardwaj', 'nishchaybhardwaj1.9@gmail.com', '•', '+', '91', '9325046223', '•', 'Portfolio', 'EDUCATION', 'BRACT', '’', 's', 'Vishwakarma', 'Institute', 'of', 'Information', 'Technology', ',', 'Pune', 'Oct', '2022', '–', 'May', '2026', 'Bachelor', 'of', 'Technology', ',', 'Computer', 'Science', '-', 'Artificial', 'Intelligence', 'CGPA', ':', '9.02', 'Relevant', 'coursework', ':', 'Machine', 'Learning', ',', 'Artificial', 'Intelligence', ',', 'Deep', 'Learning', ',', 'Data', 'Structures', 'and', 'Algorithms', ',', 'Web', 'Development', ',', 'Database', 'Management', 'Asian', 'College', 'of', 'Science', 'and', 'Commerce', ',', 'Pune', 'Apr', '2020', '–', 'May', '2021', '12th', 'Standard', 'Percentage', ':', '80.6', '%', 'INTERNSHIP', 'EXPERIENCE', 'Ratnamukund', 'HealthCare', 'Foundation', '2024', '(', 'Latest', ')', 'Full', 'Stack', 'Developer', '•', 'Developed', 'a', 'website', 'using', 'Next.js', 'and', 'Tailwind', 'CSS', 'for', 'frontend', ',', 'and', 'Strapi', 'with', 'MySQL', 'for', 'backend', '.', '•', 'Integrated', 'APIs', '(', 'OpenStreetMap', ',', 'Leaflet', ',', 'Meta', 'Console', ')', 'and', 'used', 'Git', 'for', 'version', 'control', 'and', 'Vercel', 'for', 'deployment', '.', 'PROJECTS', '&', 'EXTRACURRICULAR', 'Human', 'Pose', 'Estimation', 'using', 'Machine', 'Learning', 'May', '2024', '•', 'Compared', 'models', 'of', 'MoveNet', 'and', 'YOLOv', '8', 'for', 'classifying', 'yoga', 'poses', '(', 'downdog', ',', 'goddess', ',', 'tree', ',', 'plank', ',', 'warrior', ')', ',', 'concluding', 'that', 'MoveNet', 'achieved', 'higher', 'accuracy', '.', '•', 'Employed', 'Python', ',', 'TensorFlow', ',', 'and', 'OpenCV', ',', 'enhancing', 'understanding', 'of', 'model', 'evaluation', 'and', 'accuracy', 'metrics', '.', 'Smart', 'Campus', 'Management', 'System', 'September', '2024', '•', 'Developed', 'an', 'attendance', 'tracking', 'system', 'using', 'OpenCV', 'face', 'recognition', 'and', 'a', 'chatbot', '-', 'powered', 'timetable', 'generator', 'with', 'Bard', 'API', '.', 'Used', 'Next.js', ',', 'Tailwind', 'CSS', ',', 'and', 'Strapi', 'to', 'create', 'an', 'intuitive', 'user', 'interface', 'and', 'backend', 'for', 'efficient', 'data', 'handling', '.', 'J', '.', 'P', '.', 'Morgan', 'Software', 'Engineering', 'Virtual', 'Experience', '(', 'Forage', ')', 'October', '2024', '•', 'Set', 'up', 'a', 'local', 'dev', 'environment', 'and', 'used', 'JPMorgan', 'Chase', '’', 's', 'open', '-', 'source', 'library', ',', 'Perspective', ',', 'to', 'generate', 'a', 'live', 'graph', 'that', 'displays', 'data', 'feed', ',', 'supporting', 'traders', 'in', 'monitoring', 'data', 'in', 'real', '-', 'time', '.', 'Activity', 'July', '2023', '–', 'October', '2024', '•', 'Worked', 'on', 'Human', 'Pose', 'Estimation', 'at', 'Hacknovate', '-', '2k24', 'and', 'Smart', 'Campus', 'Management', 'in', 'Vortexa', 'Hackathon', '.', '•', 'Presented', 'chatbot', 'implementation', 'for', 'Railway', 'Industry', 'at', 'Smart', 'India', 'Hackathon', '.', 'Leadership', 'experience', 'September', '2024', '-', 'Present', '•', 'Web', 'Development', 'Head', 'of', 'CodeChef', 'Forum', 'at', 'VIIT', '.', '•', 'Participated', 'in', 'a', 'leadership', 'camp', 'organized', 'by', 'VIIT', ',', 'focusing', 'on', 'team', '-', 'building', 'and', 'leadership', 'skills', 'development', '.', 'RESEARCH', 'PAPER', '&', 'PUBLICATIONS', 'Paper', 'Title', ':', '\"', 'Human', 'Pose', 'Estimation', 'using', 'Machine', 'Learning', '\"', 'October', '2024', '•', 'Presented', 'on', 'October', '16', ',', '2024', ',', 'at', 'ASCIS', '2024', '(', 'Springer', ')', '.', 'SKILLS', 'Programming', 'Languages', ':', 'Python', ',', 'C', ',', 'C', '+', '+', ',', 'Java', 'Artificial', 'Intelligence', ':', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', ',', 'Computer', 'Vision', '(', 'Image', 'Classification', ',', 'Object', 'Detection', ')', ',', 'Reinforcement', 'Learning', 'Machine', 'Learning', ':', 'TensorFlow', ',', 'Keras', ',', 'scikit', '-', 'learn', ',', 'PyTorch', 'Web', 'Development', ':', 'HTML', ',', 'CSS', ',', 'JavaScript', ',', 'React.js', ',', 'Next.js', ',', 'Express.js', ',', 'Node.js', ',', 'Tailwind', ',', 'Flask', 'Databases', ':', 'MySQL', ',', 'MongoDB', 'DevOps', '&', 'Software', 'Engineering', ':', 'Agile', 'Methodologies', ',', 'Continuous', 'Integration', '/', 'Continuous', 'Deployment', '(', 'CI', '/', 'CD', ')', ',', 'Version', 'Control', '(', 'Git', ',', 'GitHub', ')', ',', 'Jira', ',', 'Kanban', ',', 'Docker', 'RESTful', 'APIs', ':', 'Experience', 'with', 'Postman', 'for', 'API', 'testing', 'and', 'documentation', 'Soft', 'Skills', ':', 'Problem', '-', 'solving', ',', 'critical', 'thinking', ',', 'collaboration', ',', 'communication', ',', 'determination', 'CERTIFICATIONS', '•', 'IBM', 'Certified', 'for', 'DevOps', 'and', 'Software', 'Engineering', '•', 'NVIDIA', 'Certified', 'for', 'Fundamentals', 'of', 'Deep', 'Learning', '•', 'CDAC', 'Certified', 'for', 'Basic', 'Certification', 'Course', 'in', 'Artificial', 'Intelligence', '•', 'Skolar', 'Certified', 'for', 'Full', 'Stack', 'Web', 'Development', '•', 'Infosys', 'Certified', 'for', 'Python', 'Fundamentals', 'LINKS', '•', 'GitHub', '-', 'NishchayBhardwaj', '•', 'LinkedIn', '-', 'nishchay', '-', 'bhardwaj', '•', 'LeetCode', '-', 'Nishchay', '-', 'Bhardwaj', '•', 'Coding', 'Ninjas', '-', 'nishchay', 'bhardwaj']\n",
      "MWETokenizer (basic): ['Nishchay', 'Bhardwaj', 'nishchaybhardwaj1.9@gmail.com', '•', '+91', '9325046223', '•', 'Portfolio', 'EDUCATION', 'BRACT’s', 'Vishwakarma', 'Institute', 'of', 'Information', 'Technology,', 'Pune', 'Oct', '2022', '–', 'May', '2026', 'Bachelor', 'of', 'Technology,', 'Computer', 'Science', '-', 'Artificial', 'Intelligence', 'CGPA:', '9.02', 'Relevant', 'coursework:', 'Machine', 'Learning,', 'Artificial', 'Intelligence,', 'Deep', 'Learning,', 'Data', 'Structures', 'and', 'Algorithms', ',', 'Web', 'Development,', 'Database', 'Management', 'Asian', 'College', 'of', 'Science', 'and', 'Commerce,', 'Pune', 'Apr', '2020', '–', 'May', '2021', '12th', 'Standard', 'Percentage:', '80.6%', 'INTERNSHIP', 'EXPERIENCE', 'Ratnamukund', 'HealthCare', 'Foundation', '2024', '(Latest)', 'Full', 'Stack', 'Developer', '•', 'Developed', 'a', 'website', 'using', 'Next.js', 'and', 'Tailwind', 'CSS', 'for', 'frontend,', 'and', 'Strapi', 'with', 'MySQL', 'for', 'backend.', '•', 'Integrated', 'APIs', '(OpenStreetMap,', 'Leaflet,', 'Meta', 'Console)', 'and', 'used', 'Git', 'for', 'version', 'control', 'and', 'Vercel', 'for', 'deployment.', 'PROJECTS', '&', 'EXTRACURRICULAR', 'Human', 'Pose', 'Estimation', 'using', 'Machine', 'Learning', 'May', '2024', '•', 'Compared', 'models', 'of', 'MoveNet', 'and', 'YOLOv8', 'for', 'classifying', 'yoga', 'poses', '(downdog,', 'goddess,', 'tree,', 'plank,', 'warrior),', 'concluding', 'that', 'MoveNet', 'achieved', 'higher', 'accuracy.', '•', 'Employed', 'Python', ',', 'TensorFlow', ',', 'and', 'OpenCV', ',', 'enhancing', 'understanding', 'of', 'model', 'evaluation', 'and', 'accuracy', 'metrics.', 'Smart', 'Campus', 'Management', 'System', 'September', '2024', '•', 'Developed', 'an', 'attendance', 'tracking', 'system', 'using', 'OpenCV', 'face', 'recognition', 'and', 'a', 'chatbot', '-powered', 'timetable', 'generator', 'with', 'Bard', 'API.', 'Used', 'Next.js', ',', 'Tailwind', 'CSS', ',', 'and', 'Strapi', 'to', 'create', 'an', 'intuitive', 'user', 'interface', 'and', 'backend', 'for', 'efficient', 'data', 'handling.', 'J.P.', 'Morgan', 'Software', 'Engineering', 'Virtual', 'Experience', '(Forage)', 'October', '2024', '•', 'Set', 'up', 'a', 'local', 'dev', 'environment', 'and', 'used', 'JPMorgan', 'Chase’s', 'open', '-source', 'library,', 'Perspective,', 'to', 'generate', 'a', 'live', 'graph', 'that', 'displays', 'data', 'feed,', 'supporting', 'traders', 'in', 'monitoring', 'data', 'in', 'real', '-time.', 'Activity', 'July', '2023', '–', 'October', '2024', '•', 'Worked', 'on', 'Human', 'Pose', 'Estimation', 'at', 'Hacknovate', '-2k24', 'and', 'Smart', 'Campus', 'Management', 'in', 'Vortexa', 'Hackathon', '.', '•', 'Presented', 'chatbot', 'implementation', 'for', 'Railway', 'Industry', 'at', 'Smart', 'India', 'Hackathon', '.', 'Leadership', 'experience', 'September', '2024', '-', 'Present', '•', 'Web', 'Development', 'Head', 'of', 'CodeChef', 'Forum', 'at', 'VIIT', '.', '•', 'Participated', 'in', 'a', 'leadership', 'camp', 'organized', 'by', 'VIIT,', 'focusing', 'on', 'team', '-building', 'and', 'leadership', 'skills', 'development.', 'RESEARCH', 'PAPER', '&', 'PUBLICATIONS', 'Paper', 'Title:', '\"Human', 'Pose', 'Estimation', 'using', 'Machine', 'Learning', '\"', 'October', '2024', '•', 'Presented', 'on', 'October', '16,', '2024,', 'at', 'ASCIS', '2024', '(Springer).', 'SKILLS', 'Programming', 'Languages', ':', 'Python,', 'C,', 'C++,', 'Java', 'Artificial', 'Intelligence', ':', 'Natural', 'Language', 'Processing', '(NLP),', 'Computer', 'Vision', '(Image', 'Classification,', 'Object', 'Detection),', 'Reinforcement', 'Learning', 'Machine', 'Learning', ':', 'TensorFlow,', 'Keras,', 'scikit', '-learn,', 'PyTorch', 'Web', 'Development', ':', 'HTML,', 'CSS,', 'JavaScript,', 'React.js,', 'Next.js,', 'Express.js,', 'Node.js,', 'Tailwind,', 'Flask', 'Databases', ':', 'MySQL,', 'MongoDB', 'DevOps', '&', 'Software', 'Engineering', ':', 'Agile', 'Methodologies,', 'Continuous', 'Integration/Continuous', 'Deployment', '(CI/CD),', 'Version', 'Control', '(Git,', 'GitHub)', ',', 'Jira,', 'Kanban,', 'Docker', 'RESTful', 'APIs', ':', 'Experience', 'with', 'Postman', 'for', 'API', 'testing', 'and', 'documentation', 'Soft', 'Skills', ':', 'Problem', '-solving,', 'critical', 'thinking,', 'collaboration,', 'communication,', 'determination', 'CERTIFICATIONS', '•', 'IBM', 'Certified', 'for', 'DevOps', 'and', 'Software', 'Engineering', '•', 'NVIDIA', 'Certified', 'for', 'Fundamentals', 'of', 'Deep', 'Learning', '•', 'CDAC', 'Certified', 'for', 'Basic', 'Certification', 'Course', 'in', 'Artificial', 'Intelligence', '•', 'Skolar', 'Certified', 'for', 'Full', 'Stack', 'Web', 'Development', '•', 'Infosys', 'Certified', 'for', 'Python', 'Fundamentals', 'LINKS', '•', 'GitHub', '-', 'NishchayBhardwaj', '•', 'LinkedIn', '-', 'nishchay', '-bhardwaj', '•', 'LeetCode', '-', 'Nishchay', '-Bhardwaj', '•', 'Coding', 'Ninjas', '-', 'nishchay', 'bhardwaj']\n",
      "PorterStemmer Examples:\n",
      "localization: local\n",
      "jumping: jump\n",
      "running: run\n",
      "SnowballStemmer Examples:\n",
      "localization: local\n",
      "jumping: jump\n",
      "running: run\n",
      "Lemmatizer Examples:\n",
      "jumping (verb): jump \n",
      "running (verb): run \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer, TreebankWordTokenizer, PunktSentenceTokenizer, TweetTokenizer, MWETokenizer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Tokenizers\n",
    "WT = WhitespaceTokenizer()\n",
    "DT = TreebankWordTokenizer()\n",
    "PT = PunktSentenceTokenizer()\n",
    "TT = TweetTokenizer()\n",
    "MW = MWETokenizer()\n",
    "\n",
    "# Stemmers\n",
    "PS = PorterStemmer()\n",
    "SS = SnowballStemmer('english')\n",
    "\n",
    "# Lemmatizer\n",
    "WL = WordNetLemmatizer()\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to extract text from DOCX\n",
    "# def extract_text_from_docx(file_path):\n",
    "#     doc = docx.Document(file_path)\n",
    "#     text = \"\"\n",
    "#     for paragraph in doc.paragraphs:\n",
    "#         text += paragraph.text + \" \"\n",
    "#     return text\n",
    "\n",
    "# Function to process the extracted text\n",
    "def process_text(text):\n",
    "    # Tokenization\n",
    "    print(\"Whitespace Tokenizer:\", WT.tokenize(text))\n",
    "    print(\"Treebank Tokenizer:\", DT.tokenize(text))\n",
    "    print(\"Punkt Sentence Tokenizer:\", PT.tokenize(text))\n",
    "    print(\"Tweet Tokenizer:\", TT.tokenize(text))\n",
    "    print(\"MWETokenizer (basic):\", MW.tokenize(text.split()))\n",
    "\n",
    "    # Stemming examples\n",
    "    print(\"PorterStemmer Examples:\")\n",
    "    for word in ['localization', 'jumping', 'running']:\n",
    "        print(f\"{word}: {PS.stem(word)}\")\n",
    "\n",
    "    print(\"SnowballStemmer Examples:\")\n",
    "    for word in ['localization', 'jumping', 'running']:\n",
    "        print(f\"{word}: {SS.stem(word)}\")\n",
    "\n",
    "    # Lemmatization examples\n",
    "    print(\"Lemmatizer Examples:\")\n",
    "    for word in ['jumping', 'running']:\n",
    "        print(f\"{word} (verb): {WL.lemmatize(word, 'v')} \")\n",
    "\n",
    "# Example usage for PDF\n",
    "# Place the PDF file path below\n",
    "pdf_text = extract_text_from_pdf('/content/Prasad_Ghadge_CV.pdf')\n",
    "process_text(pdf_text)\n",
    "\n",
    "# Example usage for DOCX\n",
    "# Place the DOCX file path below\n",
    "# docx_text = extract_text_from_docx('example.docx')\n",
    "# process_text(docx_text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lT9rSrj8Ognl",
    "XX_eZs5Yt16r"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
